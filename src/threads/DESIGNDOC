			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Ankita Muley ankita7@ccs.neu.edu
Calvin Pomerantz calvin@ccs.neu.edu (Dropped the course, but worked with the team before dropping)
Rakesh Viswanathan rakeshv9@ccs.neu.edu
Sanat Chugh sanatc@ccs.neu.edu

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

--------------thread.h-------------------------------------------

struct thread
  {
    ...
    struct list_elem sleepelem;         /* Added a list element member named sleepelem, which indentifies this thread in the sleeping list. */ 
    int64_t wake_time;		              /* wake_time specifies the when the thread needs to wake up.   */ 
    ....
  };


/* States in a thread's life cycle. */
enum thread_status
  {
    ...
    THREAD_SLEEPING,		                /* If a thread goes to sleep, it will get new status THREAD_SLEEPING */ 
    ...
  };
--------------thread.c-------------------------------------------

...
static struct list sleeping_list;       /* Added a list named sleeping_list, which contains the threads which are sleeping for easy access. */ 
...

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

In timer_sleep(), we assert that interrupts are on. Then we call a new function, thread_sleep(ticks), located in thread.c.
In thread_sleep, we find out the current thread then turn interrupts off so that we can complete the rest of the function atomicly. 
Then, we set the status of the thread to THREAD_SLEEPING, set its wake time to ticks seconds in the future, and insert it into the sleeping list.
The sleeping list is sorted by how long until the thread wakes up; we insert the new thread in the proper place. 
The timer interrupt handler calls thread_yield(), which schedules the next thread. 
That function looks through the sleeping list to see if a thread is ready to wake up, and wakes it up if so. 
Waking a thread up, we set its state to THREAD_READY, then add it back to the ready list.

So total time need

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

Since the sleeping list is sorted by the amount of time until the thread needs to wake up, we only have to check the first thread when checking if a thread on the list is ready to wake up.

Inserting takes O(n) time. 
Waking up thread takes O(1) time. Since list is sorted.
Total time is O(n)+O(1) = O(n)

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

We turn interrupts off before entering the critical section of timer_sleep where we modify the  sleeping list.

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

If timer interuppt occur during a call to timer_sleep(),it will not affect the call.We turn off the interrupt before modifying the sleeping list and turn interrupt on when the procedure of modifying sleeping list and scheduleing next thread is complete.

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it minimizes the time required to schedule next ready thread. We also considered the design where sleeping list was not sorted,  hence making the insertion time O(1) but finding time O(n). Since insertion happens less often than search, the algorithm used by us is better because it makes search time O(1).

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread.h:
struct thread {
...
  int effective_priority; // Allows us to know without looking what our priority is
  struct lock *lock_waiting_on; // Allows threads donating to us to see if we're waiting for another lock
  struct list donors_list; // Allows us to keep effective priority of one donor while giving up another's when we release a lock
...
}

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
Each thread maintains a list of threads donating to it, and the lock that it is waiting on (or NULL if it isn't waiting on a lock).
The list of threads donating to a thread is maintained in a sorted order.

Threads: H, M, L
Locks: X, Y
X->lock_holder = L
Y->lock_holder = M
L->Donors_list = {H, M}
M->Donors_list = {H}
H->Donors_list = {}

     Waits on lock
[H] ---------------> [Y] (held by M)
 |
 |
 | Donates to
 |
 |
 V        Waits on lock
 --->[M] ---------------> [X] (held by L)
      |
      |
      | Donates H's priority to
      |
      |
      V
     [L]

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

For a semaphore or a lock (locks use semaphores, so they are treated equivalently),
we keep the list of threads waiting to acquire the semaphore sorted by effective priority. 
Then, just before we find the first thread we sort one more time (merge sort is effective on nearly-sorted lists, so this should be fairly fast).

For a condvar, we instead sort the list of semaphores by the maximum effective priority among threads waiting on those semaphores .
Then we take the semaphore with the maximum effective priority thread waiting on that semaphore, and wake up the corresponding highest-priority thread.
We also keep the ready list sorted, and always wake up the thread with the greatest effective priority when waking up a thread.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

- First, we make sure the donor is not the receiver, and that interrupts are off.
- Then, we remove the donor thread from any list of threads it may have been donating to, 
- then place it in a sorted spot on the receiver's list of threads donating to it. O(n)
  - This is necessary for the case of nested donation - the donor thread will already be on the receiving thread's donors list, and placing something onto a list it's already on causes problems. Also, it needs to be resorted in that case.
- Then, we set the receiving thread's effective priority to the maximum of its effective priority and the effective priority of the donor thread
- Then, if the receiving thread was on the ready list, we remove it and put it back on in its new location (the ready list needs to stay sorted).O(1) time.
- Then, we check if the receiving thread was waiting on a lock. If it was, it recursively donates its new priority to the thread it was waiting on.
- The depth variable is incremented each recursion. We don't enter the recursive call unless depth is less than the constant maximum depth.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

- First, we perform some safety and sanity checks and turn interrupts off.
- Then, we recalculte the current thread's (thread releasing the lock) effective priority:
  - If the current thread's (thread releasing the lock) donors list is not empty:
    - Iterate through that list. O(n)
    - For each thread on the list, remove it from the list if it's waiting on the lock we're releasing. O(1)
      It's no longer donating priority to us.
    - Then, if the donors list is still not empty, take the first element remaining on that list and set our effective priority to be the maximum of that thread's effective priority and our priority. If the donors list is now empty, set our effective priority to be our priority.
  - If the current thread's donors list was already empty, simply set its effective priority to be its priority.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it. Can you use a lock to avoid
>> this race?

There is a race if a thread sets its priority while another thread attempts to donate its priority to the thread setting priority. The resulting effective priority may become the maximum of the thread that previously had the highest priority amongst donating threads and the current thread's priority. This is avoided by turning interrupts off during thread_set_priority - we can now be sure that that function call will complete atomicly.
A lock cannot be used to avoid this race. If thread A is inside thread_set_priority, and has some priority change lock, and thread B attempts to donate its priority to thread A, it will need to wait for A to relinquish the priority change lock. To speed this process up, B would attempt to donate its priority to A. Since A has its priority change lock, B will need to wait for A to relinquish the priority change lock....

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

We chose this design because it allows us to easily figure out what our priority should be when we relinquish donated priority. Since we keep the list of donor threads sorted, we can simply take the maximum of our priority and the effective priority of the first element of that list as our effective priority when we need to check.
We considered a design in which locks kept track of each thread waiting on them. Our design is superior because in that design, to relinquish priority it would be necessary to look through each lock we are holding and not giving up, find the highest priority thread of each, and compare the priorities of each of those.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> hard

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Yes

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Remove the refernce to BSD schedular. It mislead us.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
